{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.linalg as la\n",
    "from random import randint\n",
    "%matplotlib inline\n",
    "%precision 7\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(n):\n",
    "    \"\"\" takes a number n and generates 5 times n data points with pre-specified 5 clusters.\"\"\"\n",
    "    mean = [4, 8, 11]\n",
    "    cov = [[1, 0.7, 0.5], [0.7, 1, 0.5], [0.5, 0.5, 1]]\n",
    "    data0 = np.random.multivariate_normal(mean, cov, n)\n",
    "    data0 = np.hstack((data0, np.ones((data0.shape[0],1))))\n",
    "    mean1 = [6, 12, 8]\n",
    "    cov1 = [[1, 0.5, 0.5], [0.5, 1, 0.5], [0.5, 0.5, 1]]\n",
    "    data1 = np.random.multivariate_normal(mean1, cov1, n)\n",
    "    data1 = np.hstack((data1, np.ones((data1.shape[0],1)) * 2))\n",
    "    mean2 = [10, 13, 13]\n",
    "    cov2 = [[1, 0.5,0.5], [0.5, 1, 0.3], [0.5, 0.3, 1]]\n",
    "    data2 = np.random.multivariate_normal(mean2, cov2, n)\n",
    "    data2 = np.hstack((data2, np.ones((data2.shape[0],1)) * 3))\n",
    "    mean3 = [13, 10, 18.5]\n",
    "    cov3 = [[1, 0.5,0.5], [0.5, 1, 0.5], [0.5, 0.5, 1]]\n",
    "    data3 = np.random.multivariate_normal(mean3, cov3, n)\n",
    "    data3 = np.hstack((data3, np.ones((data3.shape[0],1)) * 4))\n",
    "    mean4 = [4, 6, 6]\n",
    "    cov4 = [[1, 0.5,0.5], [0.5, 1, 0.5], [0.5, 0.5, 1]]\n",
    "    data4 = np.random.multivariate_normal(mean4, cov4, n)\n",
    "    data4 = np.hstack((data4, np.ones((data4.shape[0],1)) * 5))\n",
    "    data = np.vstack((data0, data1, data2, data3,data4))\n",
    "    np.random.shuffle(data)\n",
    "    #print (data.shape)\n",
    "    XX = data [:,0:3]\n",
    "    data [:,3] = data [:,3]-1\n",
    "    yy = data [:,3]\n",
    "    return(XX,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator2(n):\n",
    "    \"\"\" takes a number n and generates 3 times n data points with pre-specified 3 clusters.\"\"\"\n",
    "    mean = [20, 20]\n",
    "    cov = [[1, 0.7], [0.7, 1]]\n",
    "    data0 = np.random.multivariate_normal(mean, cov, n)\n",
    "    data0 = np.hstack((data0, np.ones((data0.shape[0],1))))\n",
    "    mean1 = [10, 10]\n",
    "    cov1 = [[1, 0.5], [0.5, 1]]\n",
    "    data1 = np.random.multivariate_normal(mean1, cov1, n)\n",
    "    data1 = np.hstack((data1, np.ones((data1.shape[0],1)) * 2))\n",
    "    2\n",
    "    mean2 = [0, 0]\n",
    "    cov2 = [[1, 0.5], [0.5, 1]]\n",
    "    data2 = np.random.multivariate_normal(mean2, cov2, n)\n",
    "    data2 = np.hstack((data2, np.ones((data2.shape[0],1)) * 3))\n",
    "    data = np.vstack((data0, data1, data2))\n",
    "    np.random.shuffle(data)\n",
    "    #print (data.shape)\n",
    "    XX = data [:,0:2]\n",
    "    data [:,2] = data [:,2]-1\n",
    "    yy = data [:,2]\n",
    "    return(XX,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def squared_euclidean_norm(u, axis=-1):\n",
    "    return((u**2).sum(axis))\n",
    "def euclidean_norm(u, axis=-1):\n",
    "    return(np.sqrt(squared_euclidean_norm(u, axis)))\n",
    "def squared_euclidean_dist(u, v, axis=-1):\n",
    "    \"\"\"Returns squared Euclidean distance between two vectors.\"\"\"\n",
    "    return(squared_euclidean_norm(u-v, axis))\n",
    "def min_squared_euclidean_dist(uV, v, axis=-1):\n",
    "    \"\"\"Returns the minimum of Euclidean distance between a list of vectors and a vector v\"\"\"\n",
    "    minimum_dis_array = squared_euclidean_dist(uV[0],v)\n",
    "    for tlk in range(0,len(uV)):\n",
    "        minimum_dis_array = np.minimum(squared_euclidean_dist(uV[tlk],v),minimum_dis_array)\n",
    "    return(minimum_dis_array)\n",
    "def euclidean_dist(u, v, axis=-1):\n",
    "    \"\"\"Return Euclidean distacne between two vectors.\"\"\"\n",
    "    return(np.sqrt(squared_euclidean_dist(u, v, axis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def K_Means_basic(k,DATA, initial_centroid,advanced = False, isCython =False):\n",
    "    updated_centroid = initial_centroid\n",
    "    if not advanced: ## meaning it is just a basic version, we sample 5 random points as our cluster\n",
    "        updated_centroid = DATA[np.random.choice(range(DATA.shape[0]),k), :]\n",
    "    count = 0\n",
    "    count2 = 0\n",
    "    n_feature = len(DATA[0])\n",
    "    assignment = np.ones(len(DATA))\n",
    "    assignment2 = np.zeros(len(DATA))\n",
    "    while not np.array_equal(assignment,assignment2) : ##if the labeling of cluster do not change\n",
    "        changassignment2=assignment.copy()\n",
    "    for i in range(0,len(DATA)):\n",
    "        count = count +1\n",
    "    if not isCython:\n",
    "        dist_array = euclidean_dist(updated_centroid,DATA[i]) # find the distance array if isCython:\n",
    "    dist_array = euclidean_dist_cython(updated_centroid,DATA[i])\n",
    "    closest_distance = min(dist_array)\n",
    "    closest_index = np.where(dist_array[:]==closest_distance)\n",
    "    assignment[i] = min(np.asarray(closest_index))[0]\n",
    "    for jj in range(0,k):\n",
    "        ##updates the cnetroid\n",
    "        updated_centroid[jj] = np.mean(DATA[np.where(assignment[:]==jj)][:,0:n_feature], axis=2)\n",
    "    count2 = count2 +1\n",
    "    return(updated_centroid,assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def K_Means_plusplus(k,DATA,isCython = False):\n",
    "    random_point_index = randint(0,len(DATA))\n",
    "    center = []\n",
    "    center.append(DATA[random_point_index]) #Sample a point uniformly at random from X\n",
    "    phi_x_C_vector = squared_euclidean_dist(center[0],DATA)\n",
    "    p_x = phi_x_C_vector/sum(phi_x_C_vector) #Calculate the weight probability\n",
    "    cluster2 = []\n",
    "    while len(center) < k:\n",
    "        nnn = np.random.multinomial(1,p_x).tolist() # sample a point with the weight probability\n",
    "        loc1 = nnn.index(max(nnn))\n",
    "        center.append(DATA[loc1])\n",
    "        phi_x_C_vector = min_squared_euclidean_dist(center,DATA)\n",
    "        p_x = phi_x_C_vector/sum(phi_x_C_vector) #updates the weight probability\n",
    "    return K_Means_basic(k,DATA,np.array(center),True,isCython)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Scalable_K_Means(k,l,DATA,isCython=False):\n",
    "    random_point_index = randint(0,len(DATA))\n",
    "    center = []\n",
    "    center.append(DATA[random_point_index]) #Sample a point uniformly at random from X\n",
    "    \n",
    "    phi_x_C_vector = squared_euclidean_dist(center[0],DATA)\n",
    "    p_x = (l*phi_x_C_vector) / sum(phi_x_C_vector) #Calculate the weight probability\n",
    "    \n",
    "    for itjj in range(0,int(np.log(sum(phi_x_C_vector)))):\n",
    "        uniform_p = np.random.uniform(0,1,len(DATA))\n",
    "        \n",
    "        for itj in range(0,len(DATA)):\n",
    "            if uniform_p[itj] < p_x[itj]:\n",
    "                center.append(DATA[itj]) # sample each point x<- X independently\n",
    "                \n",
    "            phi_x_C_vector = min_squared_euclidean_dist(center,DATA) \n",
    "            p_x = l*phi_x_C_vector/sum(phi_x_C_vector)\n",
    "            \n",
    "    w_x_vector = np.zeros(len(center))\n",
    "    \n",
    "    if isCython: #put if statment outside of the for loop\n",
    "        center_array = np.asarray(center)\n",
    "        for i in range(0,len(DATA)):\n",
    "            nn = euclidean_dist_cython(center_array,DATA[i]).tolist()\n",
    "            loc = nn.index(min(nn))\n",
    "            w_x_vector[loc] = w_x_vector[loc] + 1\n",
    "    if not isCython:\n",
    "        for i in range(0,len(DATA)):\n",
    "            nn = euclidean_dist(center,DATA[i]).tolist()\n",
    "            loc = nn.index(min(nn))\n",
    "            w_x_vector[loc] = w_x_vector[loc] + 1\n",
    "    \n",
    "    w_x_vector_prob = w_x_vector/sum(w_x_vector)\n",
    "    center2 = []\n",
    "    \n",
    "    while len(center2) < k:\n",
    "        nnn = np.random.multinomial(1,w_x_vector_prob).tolist() # sample a point with the weight \n",
    "        loc1 = nnn.index(max(nnn))\n",
    "        center2.append(center[loc1])\n",
    "        phi_x_C_vector = min_squared_euclidean_dist(center2,center)\n",
    "        p_x = phi_x_C_vector/sum(phi_x_C_vector)\n",
    "    #print center2\n",
    "    return(K_Means_basic(k,DATA,np.asarray(center2),True,isCython))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
